{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Working with text data\n",
    "\n",
    "文本是最常见的序列数据之一，一般理解为单词序列。由于深度学习模型并非接收原始文本作为输入，它只能处理数值张量。因此要先将文本向量化vectorize，一般有以下几种实现方法：\n",
    "\n",
    "- 将文本分割为单词，并将每个单词转换为一个向量\n",
    "- 将文本分割为字符，并将每个字符转换为一个向量\n",
    "- 提取单词或字符的n-gram，并将每个n-gram转换为一个向量。n-gram是多个相邻单词或字符的集合，n-gram之间可以重叠。\n",
    "\n",
    "将文本分解而成的单元(单词、字符或n-gram)叫作token，将文本分解为标记的过程叫作分词(tokenization)。所有文本向量化过程都是**应用某种分词方案，然后将数值向量与生成的标记相关联。**本接介绍两种方法，one-hot encoding与token embedding。\n",
    "\n",
    "n-gram的词袋模型是一种特征工程工具，不适用于深度学习模型，但对于轻量级的浅层文本处理模型(如logistic回归和random forest)是重要且不可或缺的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 One-hot encoding of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
